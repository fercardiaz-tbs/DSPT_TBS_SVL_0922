{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iNRSx2dfA5bO"
   },
   "source": [
    "## Feature Scaling: Estandarización Z-Score y escalado Min-Max "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r0ORIQYJA5bP"
   },
   "source": [
    "- Acerca de la estandarización\n",
    "- Sobre el escalado Min-Max y la estandarización\n",
    "- ¿Estandarización o escalado Min-max?\n",
    "- Estándarización o escalado Min-max, cómo podemos hacerlo en scikit-learn\n",
    "- Acercamientos de abajo a arriba, Down-top\n",
    "- El efecto de la estandarización en un PCA con un patrón de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti17xhGNA5bP"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s8eIevUaA5bQ"
   },
   "source": [
    "### Acerca de la estandarización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4iuLMzyIA5bQ"
   },
   "source": [
    "El resultado de la **estandarización** (o **normalización de la puntuación Z**) es que las características se reescalarán para que tengan las propiedades de una distribución normal estándar con:\n",
    "\n",
    "$\\mu = 0$ and $\\sigma = 1$\n",
    "\n",
    "donde $\\mu$ es la media (promedio) y $\\sigma$ es la desviación estándar de la media; las puntuaciones estándar (también llamadas puntuaciones ***z***) de las muestras se calculan de la siguiente manera:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "La normalización de las características/features para que se centren en torno a 0 con una desviación estándar de 1 no sólo es importante si estamos comparando las mediciones que tienen diferentes unidades, pero también es un requisito general para muchos algoritmos de aprendizaje automático. Intuitivamente, podemos pensar en el descenso de gradiente como un ejemplo destacado (un algoritmo de optimización utilizado a menudo en regresión logística, SVMs, perceptrones, redes neuronales, etc.); con características en diferentes escalas, ciertos pesos pueden actualizarse más rápido que otros ya que los valores de las características $x_j$ juegan un papel en las actualizaciones de los pesos:\n",
    "\n",
    "$$\\Delta w_j = - \\eta \\frac{\\partial J}{\\partial w_j} = \\eta \\sum_i (t^{(i)} - o^{(i)})x^{(i)}_{j},$$\n",
    "\n",
    "De modo que:\n",
    "\n",
    "$$w_j := w_j + \\Delta w_j,$$\n",
    "donde $\\eta$ es la tasa de aprendizaje, $t$ la etiqueta de la clase objetivo y $o$ la salida real.\n",
    "Otros ejemplos intuitivos son los algoritmos K-Nearest Neighbor y los algoritmos de agrupación que utilizan, por ejemplo, medidas de distancia euclidiana; de hecho, los clasificadores basados en árboles son probablemente los únicos clasificadores en los que el escalado de características no supone ninguna diferencia.\n",
    "\n",
    "\n",
    "\n",
    "Citando el [`scikit-learn`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) documentation:\n",
    "\n",
    "*\"Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual feature do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFSDfRzDA5bR"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5A0INeBA5bR"
   },
   "source": [
    "<a id='About-Min-Max-scaling-normalization'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nI1hkCE_A5bS"
   },
   "source": [
    "### Sobre el escalado Min-Max y la estandarización"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wVm48vnkA5bT"
   },
   "source": [
    "Un enfoque alternativo a la normalización (o estandarización) de la puntuación Z es el llamado **escalado Mín-Máx** (a menudo también llamado simplemente \"normalización\", una causa común de ambigüedades).  \n",
    "En este enfoque, los datos se escalan a un intervalo fijo, normalmente de 0 a 1. El coste de tener este intervalo limitado es que los datos se escalan a un intervalo fijo.  \n",
    "El coste de tener este rango acotado -en contraste con la normalización- es que acabaremos con desviaciones estándar más pequeñas, lo que puede suprimir el efecto de los valores atípicos.\n",
    "\n",
    "Un escalado Mín-Máx se realiza normalmente mediante la siguiente ecuación:\n",
    "\n",
    "\\begin{equation} X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QCXeBnBA5bT"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxrqn_WEA5bU"
   },
   "source": [
    "### ¿Estandarización o escalado Min-max?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pcYyZgW_A5bV"
   },
   "source": [
    "\"¿Estandarización o escalado Min-Max?\" - No hay una respuesta obvia a esta pregunta: realmente depende de la aplicación. \n",
    "\n",
    "Por ejemplo, en los análisis de agrupamiento, la normalización puede ser especialmente crucial para comparar similitudes entre características basadas en determinadas medidas de distancia. Otro ejemplo destacado es el análisis de componentes principales, en el que solemos preferir la normalización al escalado Min-Max, ya que nos interesan los componentes que maximizan la varianza (dependiendo de la pregunta y de si el PCA calcula los componentes a través de la matriz de correlaciones en lugar de la matriz de covarianzas; [pero más sobre PCA en mi artículo anterior](http://sebastianraschka.com/Articles/2014_pca_step_by_step.html)).\n",
    "\n",
    "Sin embargo, ¡esto no significa que el escalado Min-Max no sea útil en absoluto! Una aplicación popular es el procesamiento de imágenes, donde las intensidades de los píxeles tienen que normalizarse para ajustarse a un cierto rango (es decir, de 0 a 255 para la gama de colores RGB). Además, los algoritmos típicos de redes neuronales requieren datos en una escala de 0 a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzrirBRmA5bV"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kX1ITX9yA5bW"
   },
   "source": [
    "## Entandarización y escalado, cómo se hace en Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "m1B5R04aA5bW"
   },
   "source": [
    "Por supuesto, podríamos hacer uso de las capacidades de vectorización de NumPy para calcular las puntuaciones z para la normalización y para normalizar los datos utilizando las ecuaciones que se mencionaron en las secciones anteriores. Sin embargo, hay un enfoque aún más conveniente utilizando el módulo de preprocesamiento de una de las bibliotecas de aprendizaje automático de código abierto de Python [scikit-learn](http://scikit-learn.org )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWEN_OL5A5bX"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BOakFslHA5bX"
   },
   "source": [
    "Para los siguientes ejemplos y debates, utilizaremos el conjunto de datos gratuito \"Wine\" depositado en el repositorio de aprendizaje automático de la UCI  \n",
    "(http://archive.ics.uci.edu/ml/datasets/Wine)\n",
    "\n",
    "<br>\n",
    "\n",
    "<font size=\"1\">\n",
    "**Referencia:**  \n",
    "Forina, M. et al, PARVUS - An Extendible Package for Data\n",
    "Exploration, Classification and Correlation. Institute of Pharmaceutical\n",
    "and Food Analysis and Technologies, Via Brigata Salerno, \n",
    "16147 Genoa, Italy.\n",
    "\n",
    "Bache, K. & Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "91cm_5heA5bY"
   },
   "source": [
    "El conjunto de datos Wine consta de 3 clases diferentes, en las que cada fila corresponde a una muestra de vino concreta.\n",
    "\n",
    "Las etiquetas de clase (1, 2, 3) figuran en la primera columna, y las columnas 2-14 corresponden a 13 atributos (características) diferentes:\n",
    "\n",
    "1) Alcohol  \n",
    "2) Ácido málico  \n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6oF1VqrLA5bY"
   },
   "source": [
    "#### Cargando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "S6edsgZMA5bZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "ead5438b-7990-4a8f-9ac2-5e1c89c3fbfb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.io.parsers.read_csv(\n",
    "    'https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/wine_data.csv', \n",
    "     header=None,\n",
    "     usecols=[0,1,2]\n",
    "    )\n",
    "\n",
    "df.columns=['Class label', 'Alcohol', 'Malic acid']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sxm6pRQBA5bd"
   },
   "source": [
    "Como podemos ver en la tabla anterior, las características **Alcohol** (porcentaje/volumen) y **Ácido málico** (g/l) se miden en escalas diferentes, por lo que ***Escalado de características*** es necesario importante antes de cualquier comparación o combinación de estos datos.  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QvTYGjOrA5be"
   },
   "source": [
    "#### Estandardarización y Min-Max scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Alcohol', 'Malic acid']].describe().loc[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Alcohol', 'Malic acid']].describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "fVbIgf2PA5be",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_std = std_scale.transform(df[['Alcohol', 'Malic acid']])\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(df[['Alcohol', 'Malic acid']])\n",
    "df_minmax = minmax_scale.transform(df[['Alcohol', 'Malic acid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "v93uyjO_A5bh",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "6287a137-d1a3-4c99-d61d-fb5fb5cfb4d1"
   },
   "outputs": [],
   "source": [
    "print('Mean after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].mean(), df_std[:,1].mean()))\n",
    "\n",
    "      \n",
    "print('\\nStandard deviation after standardization:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_std[:,0].std(), df_std[:,1].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "6ytjA_lHA5bj",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "fc867db1-5119-49e3-e5b7-130f5376445b"
   },
   "outputs": [],
   "source": [
    "print('Min-value after min-max scaling:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_minmax[:,0].min(), df_minmax[:,1].min()))\n",
    "print('\\nMax-value after min-max scaling:\\nAlcohol={:.2f}, Malic acid={:.2f}'\n",
    "      .format(df_minmax[:,0].max(), df_minmax[:,1].max()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oFYVfTZNA5bm"
   },
   "source": [
    "#### Vamos a pintar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "77K__G6WA5bm",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "Qfm1-VqJA5br",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "9271d145-5550-43ef-fab2-b2c9180ab8cd"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot():\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    plt.scatter(df['Alcohol'], df['Malic acid'], \n",
    "            color='green', label='input scale', alpha=0.5)\n",
    "\n",
    "    plt.scatter(df_std[:,0], df_std[:,1], color='red', \n",
    "            label='Standardized [$N  (\\mu=0, \\; \\sigma=1)$]', alpha=0.3)\n",
    "\n",
    "    plt.scatter(df_minmax[:,0], df_minmax[:,1], \n",
    "            color='blue', label='min-max scaled [min=0, max=1]', alpha=0.3)\n",
    "\n",
    "    plt.title('Alcohol and Malic Acid content of the wine dataset')\n",
    "    plt.xlabel('Alcohol')\n",
    "    plt.ylabel('Malic Acid')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG7IESkRA5bu"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EbYAU0ZoA5bu"
   },
   "source": [
    "El gráfico anterior incluye los puntos de datos del vino en las tres escalas diferentes: la escala de entrada en la que se midió el contenido de alcohol en volumen-porcentaje (verde), las características normalizadas (rojo) y las características normalizadas (azul).\n",
    "En el siguiente gráfico, ampliaremos los tres ejes-escalas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2tqyHUpA5bv"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "aSSt2gUEA5bv",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "13379129-5f89-43fc-ebd1-301006a22971"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(6,14))\n",
    "\n",
    "for a,d,l in zip(range(len(ax)), \n",
    "               (df[['Alcohol', 'Malic acid']].values, df_std, df_minmax),\n",
    "               ('Input scale', \n",
    "                'Standardized [$N  (\\mu=0, \\; \\sigma=1)$]', \n",
    "                'min-max scaled [min=0, max=1]')\n",
    "                ):\n",
    "    for i,c in zip(range(1,4), ('red', 'blue', 'green')):\n",
    "        ax[a].scatter(d[df['Class label'].values == i, 0], \n",
    "                  d[df['Class label'].values == i, 1],\n",
    "                  alpha=0.5,\n",
    "                  color=c,\n",
    "                  label='Class %s' %i\n",
    "                  )\n",
    "    ax[a].set_title(l)\n",
    "    ax[a].set_xlabel('Alcohol')\n",
    "    ax[a].set_ylabel('Malic Acid')\n",
    "    ax[a].legend(loc='upper left')\n",
    "    ax[a].grid()\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "igHy0_aCA5bx"
   },
   "source": [
    "### Comparar características con diferentes escalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "price_madrid = stats.gamma.rvs(1, size=5000)*100000\n",
    "\n",
    "plt.hist(price_madrid, 70, histtype=\"stepfilled\", alpha=.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precios de casas en diferentes monedas\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "price_madrid = stats.gamma.rvs(1, size=5000)*100000\n",
    "price_london = stats.gamma(5).rvs(5000)*100000*0.87\n",
    "price_spetesbourg = stats.gamma(5).rvs(5000)*100000*90.23\n",
    "\n",
    "plt.hist(price_madrid, 70, alpha = .7)\n",
    "plt.hist(price_london, 70, alpha = .7)\n",
    "plt.hist(price_spetesbourg, 70, alpha = .7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Madrid': price_madrid,\n",
    "                  'London': price_london,\n",
    "                  'Saint Petersburg': price_spetesbourg})\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(df)\n",
    "df_minmax = minmax_scale.transform(df)\n",
    "\n",
    "plt.hist(df_minmax[:, 0], 70, histtype=\"stepfilled\", alpha=.7, label='Madrid')\n",
    "plt.hist(df_minmax[:, 1], 70, histtype=\"stepfilled\", alpha=.7, label='London')\n",
    "plt.hist(df_minmax[:, 2], 70, histtype=\"stepfilled\", alpha=.7, label='Saint Petersburg')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QIY4clVRA5bx"
   },
   "source": [
    "## Acercamientos de arriba a abajo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JqiB5GbhA5by"
   },
   "source": [
    "Por supuesto, también podemos codificar las ecuaciones para la estandarización y el escalado 0-1 Min-Max \"manualmente\". Sin embargo, los métodos de scikit-learn siguen siendo útiles si se trabaja con conjuntos de datos de prueba y de entrenamiento y se desea escalarlos por igual.\n",
    "\n",
    "E.g., \n",
    "<pre>\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)\n",
    "</pre>\n",
    "\n",
    "A continuación, realizaremos los cálculos utilizando código Python \"puro\", y una solución NumPy más conveniente, que es especialmente útil si intentamos transformar una matriz entera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq-5HSSFA5by"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sólo para recordar las ecuaciones que estamos utilizando:\n",
    "\n",
    "Normalización:\n",
    "\n",
    "\\begin{equation} z = \\frac{x - \\mu}{\\sigma}\\end{equation} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WS7Y2PoPA5by"
   },
   "source": [
    "\n",
    "Con media:\n",
    "\n",
    "\\begin{equation}\\mu = \\frac{1}{N} \\sum_{i=1}^N (x_i)\\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con desviación estándar:\n",
    "\n",
    "\\begin{equation}\\sigma = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}\\end{equation}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalado Min-Max:\n",
    "\n",
    "\\begin{equation} X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}} \\end{equation}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8np6BxSWA5bz"
   },
   "source": [
    "### Vamos con python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "5XpINxXEA5bz",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "x = [1,4,5,6,6,2,3]\n",
    "mean = sum(x)/len(x)\n",
    "std_dev = (1/len(x) * sum([ (x_i - mean)**2 for x_i in x]))**0.5\n",
    "\n",
    "z_scores = [(x_i - mean)/std_dev for x_i in x]\n",
    "\n",
    "# Min-Max scaling\n",
    "\n",
    "minmax = [(x_i - min(x)) / (max(x) - min(x)) for x_i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2O6zScLA5b1"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bbwi029aA5b1"
   },
   "source": [
    "### NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "jtpk8DKAA5b2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Standardization\n",
    "\n",
    "x_np = np.asarray(x)\n",
    "z_scores_np = (x_np - x_np.mean()) / x_np.std()\n",
    "\n",
    "# Min-Max scaling\n",
    "\n",
    "np_minmax = (x_np - x_np.min()) / (x_np.max() - x_np.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS5sTXR9A5b4"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rDx1mgDqA5b4"
   },
   "source": [
    "### Visualización:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5-Nh9EKA5b4"
   },
   "source": [
    "Sólo para asegurarnos de que nuestro código funciona correctamente, vamos a trazar los resultados a través de matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "b4j8TR7uA5b4",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "6IruhpK7A5b6",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "d443f3f0-bea5-46ab-b44d-35debc0a5624"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(10,5))\n",
    "\n",
    "y_pos = [0 for i in range(len(x))]\n",
    "\n",
    "ax1.scatter(z_scores, y_pos, color='g')\n",
    "ax1.set_title('Python standardization', color='g')\n",
    "\n",
    "ax2.scatter(minmax, y_pos, color='g')\n",
    "ax2.set_title('Python Min-Max scaling', color='g')\n",
    "\n",
    "ax3.scatter(z_scores_np, y_pos, color='b')\n",
    "ax3.set_title('Python NumPy standardization', color='b')\n",
    "\n",
    "ax4.scatter(np_minmax, y_pos, color='b')\n",
    "ax4.set_title('Python NumPy Min-Max scaling', color='b')\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "for ax in (ax1, ax2, ax3, ax4):\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTNz1_IkA5b8"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWjJU2MuA5ci"
   },
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "MylAxHQjA5ci",
    "outputId": "134cc5c4-9962-4879-ae97-9114ad3069b4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fcc_survey_df = pd.read_csv('fcc_2016_coder_survey_subset.csv', encoding='utf-8')\n",
    "fcc_survey_df[['ID.x', 'EmploymentField', 'Age', 'Income']].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oSTrEM6AA5cj"
   },
   "source": [
    "## Binning con cortes fijos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gB85yDDkA5ck"
   },
   "source": [
    "### Distribución de la edad de los desarrolladores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "1GDAI6NIA5ck",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "5e603cf7-fea4-4078-f046-f4ea26e6976e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fcc_survey_df['Age'].hist(color='#A9C5D3')\n",
    "ax.set_title('Developer Age Histogram', fontsize=12)\n",
    "ax.set_xlabel('Age', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2Bi6STxGA5cl"
   },
   "source": [
    "### Binning basado en redondeo:\n",
    "\n",
    "``` \n",
    "Age Range: Bin\n",
    "---------------\n",
    " 0 -  9  : 0\n",
    "10 - 19  : 1\n",
    "20 - 29  : 2\n",
    "30 - 39  : 3\n",
    "40 - 49  : 4\n",
    "50 - 59  : 5\n",
    "60 - 69  : 6\n",
    "  ... and so on\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "yZEV-G1pA5cm",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "f9fca4c7-ce4a-4041-eeae-4c3d8b4c2782"
   },
   "outputs": [],
   "source": [
    "fcc_survey_df['Age_bin_round'] = np.array(np.floor(np.array(fcc_survey_df['Age']) / 10.))\n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round']].iloc[1071:1076]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1PL6KvuyA5cn"
   },
   "source": [
    "### Binning basado en rangos personalizados:\n",
    "\n",
    "``` \n",
    "Age Range : Bin\n",
    "---------------\n",
    " 0 -  15  : 1\n",
    "16 -  30  : 2\n",
    "31 -  45  : 3\n",
    "46 -  60  : 4\n",
    "61 -  75  : 5\n",
    "75 - 100  : 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc_survey_df['Age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "7cfltQpAA5cn",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "b08a956d-a679-43c4-c278-37aa88806c88"
   },
   "outputs": [],
   "source": [
    "bin_ranges = [0, 15, 30, 45, 60, 75, 100]\n",
    "bin_names = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "fcc_survey_df['Age_bin_custom_range'] = pd.cut(np.array(fcc_survey_df['Age']), \n",
    "                                               bins=bin_ranges)\n",
    "fcc_survey_df['Age_bin_custom_label'] = pd.cut(np.array(fcc_survey_df['Age']), \n",
    "                                               bins=bin_ranges, labels=bin_names)\n",
    "fcc_survey_df[['ID.x', 'Age', 'Age_bin_round', \n",
    "               'Age_bin_custom_range', 'Age_bin_custom_label']].iloc[1071:1076]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_ages(x):\n",
    "    if x >= 0 and x <=15:\n",
    "        return 1\n",
    "    pass\n",
    "\n",
    "fcc_survey_df['Age_bin_custom_label'] = fcc_survey_df['Age'].apply(bin_ages)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-Numerical_Features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec2a379ed5c25334a484232182c9d38ef8bd9861e2542d0c517568c4f99a9a7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
